{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from pprint import pprint\n",
    "# from raymond hettinger modern python dicts talk - pycon oregon may 2017\n",
    "\n",
    "keys = 'guido sarah barry rachel tim'.split()\n",
    "values1 = 'blue orange green yellow red'.split()\n",
    "values2 = 'austin denver tuscon reno portland'.split()\n",
    "values3 = 'apple banna orange pear peach'.split()\n",
    "hashes = list(map(abs, map(hash, keys)))\n",
    "entries = list(zip(hashes, keys, values1))\n",
    "comb_entries = list(zip(hashes, keys, values1, values2, values3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3205703081059114744, 'guido', 'blue'),\n",
       " (4293989514786313987, 'sarah', 'orange'),\n",
       " (8459490058338865399, 'barry', 'green'),\n",
       " (6432004217604261546, 'rachel', 'yellow'),\n",
       " (3926032199644776547, 'tim', 'red')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('guido', 'blue', 'austin', 'apple'),\n",
      " ('sarah', 'orange', 'denver', 'banna'),\n",
      " ('barry', 'green', 'tuscon', 'orange'),\n",
      " ('rachel', 'yellow', 'reno', 'pear'),\n",
      " ('tim', 'red', 'portland', 'peach')]\n"
     ]
    }
   ],
   "source": [
    "# db approach - challenge is it is a linear search\n",
    "def database_linear_search():\n",
    "    pprint(list(zip(keys, values1, values2, values3)))\n",
    "    \n",
    "database_linear_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('guido', 'blue'),\n",
      "  ('sarah', 'orange'),\n",
      "  ('barry', 'green'),\n",
      "  ('rachel', 'yellow'),\n",
      "  ('tim', 'red')],\n",
      " [('guido', 'austin'),\n",
      "  ('sarah', 'denver'),\n",
      "  ('barry', 'tuscon'),\n",
      "  ('rachel', 'reno'),\n",
      "  ('tim', 'portland')],\n",
      " [('guido', 'apple'),\n",
      "  ('sarah', 'banna'),\n",
      "  ('barry', 'orange'),\n",
      "  ('rachel', 'pear'),\n",
      "  ('tim', 'peach')]]\n"
     ]
    }
   ],
   "source": [
    "# lisp approach\n",
    "def association_lists():\n",
    "    pprint([\n",
    "        list(zip(keys, values1)),\n",
    "        list(zip(keys, values2)),\n",
    "        list(zip(keys, values3))\n",
    "    ])\n",
    "association_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('guido', 'blue'), ('rachel', 'yellow')],\n",
      " [('sarah', 'orange'), ('barry', 'green'), ('tim', 'red')]]\n"
     ]
    }
   ],
   "source": [
    "# separate chaining - reduce linear search\n",
    "entries_local= list(zip(keys, values1))\n",
    "\n",
    "# not sure why this isn't working in 3.6   (it was written for 2.7)\n",
    "def separate_chaining(n):\n",
    "    buckets = [[] for i in range(n)]\n",
    "    for pair in entries_local:\n",
    "        key, value = pair\n",
    "        i = hash(key) % n\n",
    "        buckets[i].append(pair)\n",
    "    pprint(buckets)\n",
    "\n",
    "separate_chaining(2)\n",
    "#separate_chaining(4)\n",
    "#separate_chaining(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('guido', 'blue')],\n",
      " [('tim', 'red')],\n",
      " [('rachel', 'yellow')],\n",
      " [('sarah', 'orange'), ('barry', 'green')]]\n",
      "[[('guido', 'blue')],\n",
      " [],\n",
      " [],\n",
      " [('sarah', 'orange')],\n",
      " [],\n",
      " [('tim', 'red')],\n",
      " [('rachel', 'yellow')],\n",
      " [('barry', 'green')]]\n"
     ]
    }
   ],
   "source": [
    "# four people found on 1 probe, barry would take 2\n",
    "separate_chaining(4)\n",
    "# 8 you still have a single collision, lots of empty spaces\n",
    "separate_chaining(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try dynamic resizing\n",
    "\n",
    "def resize(buckets, items, n):\n",
    "    #items = self.items     # save a list of the items\n",
    "    buckets = [[] for i in range(n)]  # make a new bigger table\n",
    "    for key, value  in items:   # reinsert saved pairs\n",
    "        key = value\n",
    "        \n",
    "        \n",
    "# we do cache the hash value\n",
    "def faster_resize(buckets, items, n):\n",
    "    #items = self.items     # save a list of the items\n",
    "    buckets = [[] for i in range(n)]  # make a new bigger table\n",
    "    for hashvalue, key, value  in items:   # reinsert saved pairs\n",
    "        key = value\n",
    "# this is incredibly fast;  almost as fast as a copy\n",
    "\n",
    "\n",
    "# faster matching\n",
    "#  in OO - can not assume that __eq__ is fast\n",
    "def fast_match(key, target_key)\n",
    "    if key is target_key: return True   # fast\n",
    "    if key.hash != target_key.hash:   return False   # fast\n",
    "    return key == target_key    # slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('guido', 'blue'),\n",
      " None,\n",
      " ('rachel', 'yellow'),\n",
      " ('sarah', 'orange'),\n",
      " ('tim', 'red'),\n",
      " None,\n",
      " None,\n",
      " ('barry', 'green')]\n"
     ]
    }
   ],
   "source": [
    "# next put all the buckets in one table\n",
    "# using open addressing\n",
    "def open_addressing_linear(n):\n",
    "    table = [None] * n\n",
    "    for h, key, value in entries:\n",
    "        i = h % n\n",
    "        while table[i] is not None:\n",
    "            i = (i + 1) % n\n",
    "        table[i] = (key, value)\n",
    "    pprint(table)\n",
    "open_addressing_linear(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# deleted entries leaves a whole,  use dummy entries\n",
    "\n",
    "# Knuth - algorithm D  (1960s)\n",
    "def lookup(h, key):\n",
    "    freeslot = None\n",
    "    for h, key, value in entries:\n",
    "        i = h % n\n",
    "        while True:\n",
    "            entry = table[i]\n",
    "            if entry == FREE:\n",
    "                return entry if freeslot is None else freeslot\n",
    "            elif entry == DUMMY:\n",
    "                if freeslot is None:\n",
    "                    freeslot = i  # remember where the dummy is\n",
    "            elif fast_match(key, entry.key):\n",
    "                return entry\n",
    "            i = (i + 1) % n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'tim' collided with 4293989514786313987\n",
      "'tim' collided with 4293989514786313987\n",
      "'tim' collided with 4293989514786313987\n",
      "'tim' collided with 6432004217604261546\n",
      "'tim' collided with 3205703081059114744\n",
      "'tim' collided with 6432004217604261546\n",
      "[(3205703081059114744, 'guido', 'blue'),\n",
      " (3926032199644776547, 'tim', 'red'),\n",
      " (6432004217604261546, 'rachel', 'yellow'),\n",
      " (4293989514786313987, 'sarah', 'orange'),\n",
      " None,\n",
      " None,\n",
      " None,\n",
      " (8459490058338865399, 'barry', 'green')]\n"
     ]
    }
   ],
   "source": [
    "# multiple hashing\n",
    "# with linaer probabing we can end up with catastrophic linear pile-up\n",
    "#  solution is to re-hash on both full values and # of probes\n",
    "\n",
    "# Tim Peters code\n",
    "def open_address_multihash(n):\n",
    "    table = [None] * n\n",
    "    for h, key, value in entries:\n",
    "        perturb = h\n",
    "        i = h % n\n",
    "        while table[i] is not None:\n",
    "            print('%r collided with %r' % (key, table[i][0]))\n",
    "            i = (5 * i + perturb + 1) % n\n",
    "            perturb >>= 5   # bit shift 5  (use more of the has)\n",
    "        table[i] = (h, key, value)\n",
    "    pprint(table)\n",
    "    \n",
    "open_address_multihash(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3205703081059114744, 'guido', 'blue'),\n",
      " (4293989514786313987, 'sarah', 'orange'),\n",
      " (8459490058338865399, 'barry', 'green'),\n",
      " (6432004217604261546, 'rachel', 'yellow'),\n",
      " (3926032199644776547, 'tim', 'red')]\n",
      "[0, 4, 3, 1, None, None, None, 2]\n"
     ]
    }
   ],
   "source": [
    "# early out for lookups\n",
    "#  PEP 509 - add previate version to dict  (3.6)   Victor Stinner\n",
    "\n",
    "# Compact Dict - Raymond Tettinger\n",
    "\n",
    "def compact_and_ordered(n):\n",
    "    table = [None] * n\n",
    "    for pos, entry in enumerate(entries):\n",
    "        h = perturb = entry[0]\n",
    "        i = h % n\n",
    "        while table[i] is not None:\n",
    "            i = (5 * i + perturb + 1) % n\n",
    "            perturb >>= 5\n",
    "        table[i] = pos\n",
    "    pprint(entries)\n",
    "    pprint(table)\n",
    "compact_and_ordered(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3205703081059114744, 'guido', 'blue', 'austin', 'apple'),\n",
      " (4293989514786313987, 'sarah', 'orange', 'denver', 'banna'),\n",
      " (8459490058338865399, 'barry', 'green', 'tuscon', 'orange'),\n",
      " (6432004217604261546, 'rachel', 'yellow', 'reno', 'pear'),\n",
      " (3926032199644776547, 'tim', 'red', 'portland', 'peach')]\n",
      "[0, 4, 3, 1, None, None, None, 2]\n"
     ]
    }
   ],
   "source": [
    "# the problem is each dictionary (the one for cities and fruit is shared)\n",
    "# PEP 412 - Key Sharing solves this\n",
    "\n",
    "def shared_and_compact(n):\n",
    "    \"\"\" compact, ordered, and shared \"\"\"\n",
    "    table = [None] * n\n",
    "    for pos, entry in enumerate(comb_entries):\n",
    "        h = perturb = entry[0]\n",
    "        i = h % n\n",
    "        while table[i] is not None:\n",
    "            i = (5 * i + perturb + 1) % n\n",
    "            perturb >>= 5\n",
    "        table[i] = pos\n",
    "    pprint(comb_entries)\n",
    "    pprint(table)\n",
    "shared_and_compact(8)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# future - increase sparsity to reduce collisions\n",
    "#  can get increased sparsity \n",
    "\n",
    "# these are back to databases with index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
